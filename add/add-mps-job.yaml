apiVersion: batch/v1
kind: Job
metadata:
  name: add
spec:
  completions: 1
  parallelism: 1
  template:
    spec:
      containers:
      - name: add
        image: us.gcr.io/gracegao-gke-dev/add@sha256:011757f0253f73721463ac1cc678aa7a85f4e84e7c67723621d551ea71c5f656
        command:
        - /bin/sh
        - -c
        - nvidia-smi; /usr/local/cuda/samples/0_Simple/vectorAdd/vectorAdd;
        resources:
          limits:
            nvidia.com/gpu: 1
        volumeMounts:
        - mountPath: /tmp/nvidia-mps
          name: mps
#        env:
#        - name: CUDA_MPS_ACTIVE_THREAD_PERCENTAGE
#          value: "10"
#        - name: CUDA_MPS_PINNED_DEVICE_MEM_LIMIT
#          value: "50MB"
      restartPolicy: Never
      hostIPC: true
      volumes:
      - hostPath:
          path: /tmp/nvidia-mps
          type: Directory
        name: mps
  backoffLimit: 4

# MPS with synchronization
#  


# ------
# To start MPS on the node:
# Current compute modpe of GPU: nvidia-smi -q -d compute

# Set GPU 0 to exclusive mode:   nvidia-smi -i 0 -c EXCLUSIVE_PROCESS

# Set GPU 0 back to default mode: nvidia-smi -i 0 -c DEFAULT

# Reboot/reset GPU with new setting: nvidia-smi -i 0 -r 

# PATH=$PATH:/home/kubernetes/bin/nvidia/bin

# nvidia-cuda-mps-control -d 

# ps -ef | grep mps

# echo get_default_active_thread_percentage  | nvidia-cuda-mps-control 

# echo quit | nvidia-cuda-mps-control



